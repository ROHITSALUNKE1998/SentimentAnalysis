{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Sentiment_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTMxvjbRKUrBlDpYrdE2ps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ROHITSALUNKE1998/SentimentAnalysis/blob/main/Copy_of_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4xqKb7kExOc"
      },
      "source": [
        "# SVM Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwMjnG-dEh1z"
      },
      "source": [
        "import pandas as pd\n",
        "# train Data\n",
        "trainData = pd.read_csv(\"https://raw.githubusercontent.com/Vasistareddy/sentiment_analysis/master/data/train.csv\")\n",
        "# test Data\n",
        "testData = pd.read_csv(\"https://raw.githubusercontent.com/Vasistareddy/sentiment_analysis/master/data/test.csv\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create feature vectors\n",
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "train_vectors = vectorizer.fit_transform(trainData['Content'])\n",
        "test_vectors = vectorizer.transform(testData['Content'])\n",
        "\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "# Perform classification with SVM, kernel=linear\n",
        "classifier_linear = svm.SVC(kernel='linear')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(train_vectors, trainData['Label'])\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(test_vectors)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "# results\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "report = classification_report(testData['Label'], prediction_linear, output_dict=True)\n",
        "print('positive: ', report['pos'])\n",
        "print('negative: ', report['neg'])\n",
        "\n",
        "'''\n",
        "review = \"SUPERB, I AM IN LOVE IN THIS PHONE\"\n",
        "review_vector = vectorizer.transform([review]) # vectorizing\n",
        "x = (classifier_linear.predict(review_vector))\n",
        "if x == 'pos':\n",
        "  print('Positive')\n",
        "elif x == 'neg':\n",
        "  print('Negative')'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFa6v3KpJKyl"
      },
      "source": [
        "# Live Amazon Data Scraping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2uiYAnbJs2i"
      },
      "source": [
        "Commands to install Chrome Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDiqouuxJTeO"
      },
      "source": [
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--disable-gpu')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.binary_location = GOOGLE_CHROME_PATH\n",
        "driver = webdriver.Chrome(execution_path=CHROMEDRIVER_PATH, chrome_options=chrome_options)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKUrhDPrJ0Lb"
      },
      "source": [
        "Program to get live Amazon Review Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQxiO8yKBXF"
      },
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "linkOption = input(\"Do you want to search product with link (yes/no): \")\n",
        "\n",
        "if linkOption == 'yes' or linkOption == 'Yes' or linkOption == 'YES':\n",
        "  reviewlist = []\n",
        "\n",
        "  def get_url(search_term):\n",
        "      template = \"{}\"\n",
        "      return template.format(search_term)\n",
        "  product = input(\"Enter the Product link of which you want to get Sentiment:\")\n",
        "  #print(product)          #product search\n",
        "  url = get_url(product)  #Product link\n",
        "  driver.get(url)\n",
        "  \"\"\"Extract the collection\"\"\"\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  sub_review_url = soup.find('a', {'data-hook': 'see-all-reviews-link-foot'})\n",
        "  review_url = sub_review_url.get('href')\n",
        "  driver.get(\"https://www.amazon.in\"+review_url)\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "  reviews = soup.find_all('div', {'data-hook': 'review'})\n",
        "  for item in reviews:  \n",
        "      review = [\n",
        "      #'product': soup.title.text.replace('Amazon.in:Customer reviews:','').strip(),\n",
        "      #'title': item.find('a', {'data-hook': 'review-title'}).text.strip(),\n",
        "      #'rating': float(item.find('i', {'data-hook': 'review-star-rating'}).text.replace('out of 5 stars', '').strip()),\n",
        "      item.find('span', {'data-hook': 'review-body'}).text.strip(),\n",
        "      ]\n",
        "      #print(review)\n",
        "      reviewlist.append(review)\n",
        "  \n",
        "  \n",
        "  \n",
        "  def view_comments():\n",
        "      reviews = soup.find_all('div', {'data-hook': 'review'})\n",
        "      for item in reviews:  \n",
        "          review = [\n",
        "          #'product': soup.title.text.replace('Amazon.in:Customer reviews:','').strip(),\n",
        "          #'title': item.find('a', {'data-hook': 'review-title'}).text.strip(),\n",
        "          #'rating': float(item.find('i', {'data-hook': 'review-star-rating'}).text.replace('out of 5 stars', '').strip()),\n",
        "          item.find('span', {'data-hook': 'review-body'}).text.strip(),\n",
        "          ]\n",
        "          #print(review)\n",
        "          reviewlist.append(review)\n",
        "  for x in range(1,30):\n",
        "      next_page = soup.find('div', {'class': 'a-form-actions a-spacing-top-extra-large'})\n",
        "      next_page1 = next_page.find('li', {'class': 'a-last'})\n",
        "      next_page2 = next_page1.find('a')\n",
        "      next_page3 = next_page2.get('href')\n",
        "      driver.get(\"https://www.amazon.in\"+next_page3)\n",
        "      soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "      view_comments()\n",
        "      if not soup.find('li', {'class':'a-disabled a-last'}):\n",
        "          pass\n",
        "      else:\n",
        "          break\n",
        "  #print(*reviewlist, sep = \"\\n\")\n",
        "  df = pd.DataFrame(reviewlist)\n",
        "  df.to_excel('livedataset.xlsx', index=False)\n",
        "  print('Finished..')\n",
        "else:\n",
        "  reviewlist = []\n",
        "  def get_url(search_term):\n",
        "        \"\"\"Generate a url for a search term\"\"\"\n",
        "        template = \"https://www.amazon.in/s?k={}&ref=nb_sb_noss_2\"\n",
        "        search_term = search_term.replace(' ','+')      #To remove space given from user\n",
        "        return template.format(search_term)\n",
        "    product = input(\"Enter the Product name of which you want to get Sentiment:\")\n",
        "    print(product)          #product search\n",
        "    url = get_url(product)  #Product link\n",
        "    driver.get(url)\n",
        "    \"\"\"Extract the collection\"\"\"\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    firstResult = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
        "    len(firstResult)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRfwAJDQMIIn"
      },
      "source": [
        "# Predict the Review Sentiment SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV-RsO2vMYC-"
      },
      "source": [
        "count_pos = 0\n",
        "count_neg = 0\n",
        "for i in range(len(reviewlist)): \n",
        "  read_review = str(reviewlist[i])\n",
        "  print(read_review)\n",
        "  review_vector = vectorizer.transform([read_review]) # vectorizing\n",
        "  x = (classifier_linear.predict(review_vector))\n",
        "  if x == 'pos':\n",
        "    count_pos = count_pos + 1\n",
        "    print('Positive')\n",
        "  elif x == 'neg':\n",
        "    count_neg = count_neg + 1\n",
        "    print('Negative')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPaNWpJEWZUh"
      },
      "source": [
        "# Final Result as per Support Vector Machine\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xukrxfiYWk0H"
      },
      "source": [
        "positive_reviews = float ((count_pos / len(reviewlist)) * 100)\n",
        "negative_reviews = float ((count_neg / len(reviewlist))*100)\n",
        "print(\"According to the Support Vector Machine(SVM) approach the product sentiment is %.2f Positive\" % positive_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4-zGtoIa-Lm"
      },
      "source": [
        "# Predict the Review Sentiment Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PxFUCnobUtR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "df=pd.read_csv(\"/content/sample_data/test.txt\",sep='\\t',names=['like','txt'])\n",
        "df.head()\n",
        "nltk.download('stopwords')\n",
        "stopset=set(stopwords.words('english'))\n",
        "vectorizer=TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii',stop_words=stopset)\n",
        "y=df.like\n",
        "x_nb_=vectorizer.fit_transform(df.txt)\n",
        "x_train, x_test, y_train, y_test= train_test_split(x_nb_,y,random_state=0)\n",
        "clf = naive_bayes.MultinomialNB()\n",
        "clf.fit(x_train, y_train)\n",
        "roc_auc_score(y_test, clf.predict_proba(x_test)[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCS_PYeMduq7"
      },
      "source": [
        "count_pos_nb = 0\n",
        "count_neg_nb = 0\n",
        "for j in range(len(reviewlist)):     \n",
        "  review_nb = np.array([str(reviewlist[j])])\n",
        "  print(review_nb)\n",
        "  review_vector_nb = vectorizer.transform(review_nb)\n",
        "  x_nb = (clf.predict(review_vector_nb))\n",
        "  if x_nb == [1]:\n",
        "    count_pos_nb = count_pos_nb + 1\n",
        "    print('Positive')\n",
        "  elif x_nb == [0]:\n",
        "    count_neg_nb = count_neg_nb + 1\n",
        "    print('Negative')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE1fJBE2lTJQ"
      },
      "source": [
        "# Final Result as per Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3c41j2JlXR9",
        "outputId": "6f3b339a-db7f-444f-eca7-7106ba8c15ad"
      },
      "source": [
        "positive_reviews_nb = float ((count_pos_nb / len(reviewlist)) * 100)\n",
        "negative_reviews_nb = float ((count_neg_nb / len(reviewlist))*100)\n",
        "print(\"According to the Naive Bayes approach the product sentiment is %.2f Positive\" % positive_reviews_nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "According to the Naive Bayes approach the product sentiment is 68.67 Positive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}