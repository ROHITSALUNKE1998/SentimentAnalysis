{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amazon _Sentiment_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpQWsAD5NkMBb4++xYkIeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ROHITSALUNKE1998/SentimentAnalysis/blob/main/amazon__Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFa6v3KpJKyl"
      },
      "source": [
        "# Live Amazon Data Scraping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2uiYAnbJs2i"
      },
      "source": [
        "Commands to install Chrome Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDiqouuxJTeO"
      },
      "source": [
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--disable-gpu')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.binary_location = GOOGLE_CHROME_PATH\n",
        "driver = webdriver.Chrome(execution_path=CHROMEDRIVER_PATH, chrome_options=chrome_options)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKUrhDPrJ0Lb"
      },
      "source": [
        "Program to get live Amazon Review Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQxiO8yKBXF"
      },
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "linkOption = input(\"Do you want to search product with link (yes/no): \")\n",
        "\n",
        "if linkOption == 'yes' or linkOption == 'Yes' or linkOption == 'YES':\n",
        "  reviewlist = []\n",
        "\n",
        "  def get_url(search_term):\n",
        "      template = \"{}\"\n",
        "      return template.format(search_term)\n",
        "  product = input(\"Enter the Product link of which you want to get Sentiment:\")\n",
        "  #print(product)          #product search\n",
        "  url = get_url(product)  #Product link\n",
        "  driver.get(url)\n",
        "  \"\"\"Extract the collection\"\"\"\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "  sub_review_url = soup.find('a', {'data-hook': 'see-all-reviews-link-foot'})\n",
        "  review_url = sub_review_url.get('href')\n",
        "  driver.get(\"https://www.amazon.in\"+review_url)\n",
        "  soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "  reviews = soup.find_all('div', {'data-hook': 'review'})\n",
        "  for item in reviews:  \n",
        "      review = [\n",
        "      #'product': soup.title.text.replace('Amazon.in:Customer reviews:','').strip(),\n",
        "      #'title': item.find('a', {'data-hook': 'review-title'}).text.strip(),\n",
        "      #'rating': float(item.find('i', {'data-hook': 'review-star-rating'}).text.replace('out of 5 stars', '').strip()),\n",
        "      item.find('span', {'data-hook': 'review-body'}).text.strip(),\n",
        "      ]\n",
        "      #print(review)\n",
        "      reviewlist.append(review)\n",
        "  \n",
        "  \n",
        "  \n",
        "  def view_comments():\n",
        "      reviews = soup.find_all('div', {'data-hook': 'review'})\n",
        "      for item in reviews:  \n",
        "          review = [\n",
        "          #'product': soup.title.text.replace('Amazon.in:Customer reviews:','').strip(),\n",
        "          #'title': item.find('a', {'data-hook': 'review-title'}).text.strip(),\n",
        "          #'rating': float(item.find('i', {'data-hook': 'review-star-rating'}).text.replace('out of 5 stars', '').strip()),\n",
        "          item.find('span', {'data-hook': 'review-body'}).text.strip(),\n",
        "          ]\n",
        "          #print(review)\n",
        "          reviewlist.append(review)\n",
        "  for x in range(1,30):\n",
        "      next_page = soup.find('div', {'class': 'a-form-actions a-spacing-top-extra-large'})\n",
        "      next_page1 = next_page.find('li', {'class': 'a-last'})\n",
        "      next_page2 = next_page1.find('a')\n",
        "      next_page3 = next_page2.get('href')\n",
        "      driver.get(\"https://www.amazon.in\"+next_page3)\n",
        "      soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "      view_comments()\n",
        "      if not soup.find('li', {'class':'a-disabled a-last'}):\n",
        "          pass\n",
        "      else:\n",
        "          break\n",
        "  #print(*reviewlist, sep = \"\\n\")\n",
        "  df = pd.DataFrame(reviewlist)\n",
        "  df.to_excel('livedataset.xlsx', index=False)\n",
        "  print('Finished..')\n",
        "else:\n",
        "  reviewlist = []\n",
        "  def get_url(search_term):\n",
        "        \"\"\"Generate a url for a search term\"\"\"\n",
        "        template = \"https://www.amazon.in/s?k={}&ref=nb_sb_noss_2\"\n",
        "        search_term = search_term.replace(' ','+')      #To remove space given from user\n",
        "        return template.format(search_term)\n",
        "    product = input(\"Enter the Product name of which you want to get Sentiment:\")\n",
        "    print(product)          #product search\n",
        "    url = get_url(product)  #Product link\n",
        "    driver.get(url)\n",
        "    \"\"\"Extract the collection\"\"\"\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    firstResult = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
        "    len(firstResult)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}